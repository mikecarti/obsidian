We can summarize the Gauss-Markov Assumptions succinctly in algebra, by saying that a [[Linear Regression]] model represented by

$$
y_{i } = x_{i}\beta + \epsilon_{i}
$$
and generated by the ordinary least squares estimate is the best linear unbiased estimate (BLUE) possible if
- $E[{ε_i}] = 0, \quad i = 1, … , N$
- $\{ε_1…ε_n\}$ and $\{x_1,…,x_N\}$ are independent
- $cov({ε_i, ε_j}) = 0, \quad i, j = 1,…, N \quad I ≠ j.$
- $Var(\epsilon_{i}) = \sigma^{2}$ ([[Homoscedasticity]])