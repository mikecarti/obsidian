When our gradients become too small / big because weights are too small / big. 


A huge problem for RNN, where weight matrix for transition from $i$-th iteration to $i+1$ iteration stays the same which results in multiplicative effect $W_{2}^{N+1}$. where N is the number of input data.