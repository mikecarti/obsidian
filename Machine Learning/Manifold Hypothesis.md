
All natural data lies on a low-dimensional [[Manifold]] in the high-dimensional space, where it is encoded. 

It’s accurate, and it’s the reason why [[Deep Learning]] works. It’s true for human faces, tree morphology, the sounds of the human voice, and even natural language.

## Implications of hypothesis
- ML models have to fit relatively trivial, low-dimensional, highly structured subspaces (subsets of space) within their potential input space ([[Latent Space|latent]] [[Manifold|manifolds]])
- Within one of manifolds, it is always possible to interpolate between two inputs. So you can continuously transfer from one input to another (morph one into another via a continuous path along which all points fall on the manifold).