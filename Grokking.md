[[Neural Network]] will generalize all of the sudden, after overfitting after training for a long time. 

![[Pasted image 20240206145221.png]]

## Algorithmic Datasets
For now it was only tested on algorythmic datasets (synthetically generated) in the case of initial paper, it is a table of binary operations.

## Parameters of experiment
120x120 matrix dataset.
[[Weight Decay]] helps a LOT.

## In Contrast
Contrary to [[Symbolic Regression]] and [[Enternal Graph with Reasoning]], we do not try to force the model into figuring out the rule, but it figures it by itself.

## A related idea
![[Double Gradient Descent]]